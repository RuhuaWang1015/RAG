{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies**"
      ],
      "metadata": {
        "id": "GMFyFYyGZgrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain tiktoken openai chromadb langchainhub bs4 ragas"
      ],
      "metadata": {
        "id": "OTIHc7TRZrmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "UWhBnxiUZ3hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "# Set API key for OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever"
      ],
      "metadata": {
        "id": "fANAe4ReZ8fB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Baseline RAG with LangChain**"
      ],
      "metadata": {
        "id": "XL9OflM6rBJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1: Load data**"
      ],
      "metadata": {
        "id": "sWhgn4FPalRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# URLs of the text files\n",
        "url_paul_graham = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/paul_graham_essay.txt\"  # Replace with actual URL\n",
        "url_state_of_the_union = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
        "\n",
        "# Function to download and save a text file\n",
        "def download_text(url, filename):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, \"w\") as file:\n",
        "            file.write(response.text)\n",
        "    else:\n",
        "        print(f\"Failed to download {filename}\")\n",
        "\n",
        "# Download texts\n",
        "download_text(url_paul_graham, \"paul_graham_essay.txt\")\n",
        "download_text(url_state_of_the_union, \"state_of_the_union.txt\")\n",
        "\n",
        "# Load documents using TextLoader\n",
        "loaders = [\n",
        "    TextLoader(\"./paul_graham_essay.txt\"),\n",
        "    TextLoader(\"./state_of_the_union.txt\"),\n",
        "]\n",
        "\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())\n",
        ""
      ],
      "metadata": {
        "id": "eK00zmwiakor"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2:Split data**"
      ],
      "metadata": {
        "id": "PaWlYoJ4bM-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=100, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "kmCg3iEUbMMl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3:Store**"
      ],
      "metadata": {
        "id": "lLl4Z_XpbjEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "djKW1IehbvI2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4: Retrieve**"
      ],
      "metadata": {
        "id": "svUYMIqIcLUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
      ],
      "metadata": {
        "id": "lHvoVpIwcJXJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5: Generate**"
      ],
      "metadata": {
        "id": "rJHsO6B5deI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
        "\n",
        "#query vector store\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"Done!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\",\"question\"]\n",
        "  )\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  chain_type_kwargs={\"prompt\": PROMPT},\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True\n",
        "                                  )"
      ],
      "metadata": {
        "id": "Ps_UTAlodrNy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_1 = \"What did the president say about Justice Breyer?\"\n",
        "result_1 = qa_chain({\"query\": question_1})\n",
        "result_1[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MKxMAdQabjQN",
        "outputId": "a7f32b9c-026d-4de5-ee50-a4ef9efb18b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The president thanked Justice Breyer for his service and mentioned that he is retiring from the United States Supreme Court. Done!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_2 = \"What did the author do after his time at Y Combinator?\"\n",
        "result_2 = qa_chain({\"query\": question_2})\n",
        "result_2[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zwjc8caWlYw-",
        "outputId": "a1390cdc-0090-4fe2-daf4-a9ad72ef4c85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The author stopped working on Arc and focused on writing essays and working on YC. Done!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6: Evaluation**"
      ],
      "metadata": {
        "id": "2E8uo4XhY72Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.metrics import faithfulness, answer_relevancy, context_relevancy, context_recall\n",
        "from ragas.langchain import RagasEvaluatorChain\n",
        "import pandas as pd\n",
        "\n",
        "# make eval chains, as there is no GroundTruth, we only use these three metrics\n",
        "eval_chains = {\n",
        "    m.name: RagasEvaluatorChain(metric=m)\n",
        "    for m in [faithfulness, answer_relevancy, context_relevancy]\n",
        "}\n",
        "\n",
        "\n",
        "def display_eval(results):\n",
        "    eval_data = []\n",
        "    for i, result in enumerate(results, 1):\n",
        "        eval_row = {\"Result\": f\"Result {i}\"}\n",
        "        for name, eval_chain in eval_chains.items():\n",
        "            score_name = f\"{name}_score\"\n",
        "            score = eval_chain(result)[score_name]\n",
        "            formatted_score = f\"{score:.4f}\"\n",
        "            eval_row[score_name] = formatted_score\n",
        "        eval_data.append(eval_row)\n",
        "    eval_df = pd.DataFrame(eval_data)\n",
        "    display(eval_df)\n",
        "\n",
        "display_eval([result_1, result_2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "TEBSGvuqY-Ze",
        "outputId": "393e65bb-bc3f-412a-f4bc-291ad0dfb2de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Result faithfulness_score answer_relevancy_score context_relevancy_score\n",
              "0  Result 1             1.0000                 0.8710                  0.0145\n",
              "1  Result 2             1.0000                 0.8349                  0.0000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d625170f-fada-44f6-b2b4-76ed6cc6d41b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Result</th>\n",
              "      <th>faithfulness_score</th>\n",
              "      <th>answer_relevancy_score</th>\n",
              "      <th>context_relevancy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Result 1</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8710</td>\n",
              "      <td>0.0145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Result 2</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8349</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d625170f-fada-44f6-b2b4-76ed6cc6d41b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d625170f-fada-44f6-b2b4-76ed6cc6d41b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d625170f-fada-44f6-b2b4-76ed6cc6d41b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60e9cac7-5aa9-4d20-b150-53f654ad0c3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60e9cac7-5aa9-4d20-b150-53f654ad0c3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60e9cac7-5aa9-4d20-b150-53f654ad0c3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploration 1: Improving RAG: experiment with different chunk sizes**\n",
        "Enhancing the performance of the Retrieval-Augmented Generation (RAG) model by experimenting with various document chunk sizes.\n",
        "We systematically alter the size of the chunks into which each document is split. By testing different sizes, we aim to determine the optimal chunk length that strikes a balance between providing enough context for accurate retrieval and being concise enough for efficient processing."
      ],
      "metadata": {
        "id": "gF50HCgscbeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_with_chunk_sizes(chunk_sizes, docs, question,prompt):\n",
        "    results = []\n",
        "\n",
        "    for chunk_size in chunk_sizes:\n",
        "        # print(f\"Experimenting with chunk size: {chunk_size}\")\n",
        "\n",
        "        # Splitting the document\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size, chunk_overlap=100, add_start_index=True\n",
        "        )\n",
        "        all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "        # Creating vectorstore and retriever\n",
        "        vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
        "        retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "        # Setting up and invoking the QA chain\n",
        "        qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0),\n",
        "                                               chain_type=\"stuff\",\n",
        "                                               chain_type_kwargs={\"prompt\": prompt},\n",
        "                                               retriever=retriever,\n",
        "                                               return_source_documents=True\n",
        "                                              )\n",
        "        result = qa_chain({\"query\": question})\n",
        "        results.append({\n",
        "            \"chunk_size\": chunk_size,\n",
        "            \"response\": result\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_evaluation_results(results):\n",
        "    # Setup for evaluation\n",
        "    eval_chains = {\n",
        "        m.name: RagasEvaluatorChain(metric=m)\n",
        "        for m in [faithfulness, answer_relevancy, context_relevancy]\n",
        "    }\n",
        "\n",
        "    for result in results:\n",
        "        print(f\"Chunk size: {result['chunk_size']}\")\n",
        "        print(result['response'][\"result\"])\n",
        "        for name, eval_chain in eval_chains.items():\n",
        "            score_name = f\"{name}_score\"\n",
        "            eval_result = eval_chain(result['response'])\n",
        "            formatted_score = \"{:.4f}\".format(eval_result[score_name])\n",
        "            print(f\"{score_name}: {formatted_score}\")\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "i_CivareZIpc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of chunk sizes to experiment with\n",
        "chunk_sizes = [200, 400, 800,1000]\n",
        "\n",
        "# Run the experiments using question_1\n",
        "experiment_results = experiment_with_chunk_sizes(chunk_sizes,  docs, question_1,PROMPT)\n",
        "display_evaluation_results(experiment_results)\n",
        "\n",
        "# Run the experiments using question_2\n",
        "experiment_results = experiment_with_chunk_sizes(chunk_sizes, docs, question_2,PROMPT)\n",
        "display_evaluation_results(experiment_results)"
      ],
      "metadata": {
        "id": "slWxMz3eJH_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1: Justice Stephen Breyer Query Analysis\n",
        "\n",
        "| Chunk Size | Faithfulness Score | Answer Relevancy Score | Context Relevancy Score | Observations |\n",
        "|------------|--------------------|------------------------|-------------------------|--------------|\n",
        "| 200        | 0.6667             | 0.9105                 | 0.0741                  | Lower faithfulness and context relevancy, high answer relevancy. |\n",
        "| 400        | 1.0000             | 0.9426                 | 0.1000                  | High faithfulness and answer relevancy, moderate context relevancy. |\n",
        "| 800        | 1.0000             | 0.9426                 | 0.0741                  | High faithfulness and answer relevancy, moderate context relevancy. |\n",
        "| 1000       | 0.6667             | 0.9105                 | 0.0571                  | Lower faithfulness and context relevancy, high answer relevancy. |\n",
        "\n",
        "### Question 2: Y Combinator Query Analysis\n",
        "\n",
        "| Chunk Size | Faithfulness Score | Answer Relevancy Score | Context Relevancy Score | Observations |\n",
        "|------------|--------------------|------------------------|-------------------------|--------------|\n",
        "| 200        | 0.5000             | 1.0000                 | 0.1389                  | Lower faithfulness, high answer relevancy, low context relevancy. |\n",
        "| 400        | 1.0000             | 0.8089                 | 0.0333                  | High faithfulness, lower answer relevancy, very low context relevancy. |\n",
        "| 800        | 1.0000             | 0.8525                 | 0.0417                  | High faithfulness, moderate answer relevancy, low context relevancy. |\n",
        "| 1000       | 1.0000             | 0.8525                 | 0.0417                  | High faithfulness, moderate answer relevancy, low context relevancy. |\n",
        "\n",
        "### General Insights\n",
        "\n",
        "1. **Impact of Chunk Size**: The chunk size significantly affects the quality of answers. Medium chunk sizes (400, 800) provide a good balance between faithfulness and answer relevancy.\n",
        "2. **Faithfulness vs. Context Relevancy**: There's a noticeable trade-off between faithfulness and context relevancy. Higher faithfulness does not always correspond to a better understanding of the context.\n",
        "3. **Optimal Chunk Size**: For these queries, chunk sizes of 400 and 800 appear to yield the best overall results in terms of faithfulness and answer relevancy.\n",
        "\n",
        "### Recommendations\n",
        "\n",
        "- **Balancing Chunk Size**: Finding an optimal chunk size that balances faithfulness and relevancy is crucial. In this case, 400 or 800 seem to be effective.\n",
        "- **Detailed Context**: Providing more detailed context may help improve context relevancy scores, especially for chunk sizes where it is lower.\n",
        "- **Experimentation**: Continuously experimenting with different chunk sizes can help determine the most effective size for various types of queries and contexts.\n"
      ],
      "metadata": {
        "id": "-dXzuPeaXSI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploration 2: Improving RAG using MultiVector Retriever**\n",
        "\n",
        "Enhancing document retrieval using LangChain's MultiVectorRetriever, which stores multiple vectors for each document. This approach includes:\n",
        "\n",
        "*   Smaller Chunks: Splitting documents into smaller, individually embedded chunks for more precise retrieval.\n",
        "*   Summaries: Generating and embedding document summaries for a broader context.\n",
        "*   Hypothetical Questions: Creating questions each document can answer, embedding these for query-relevant retrievals."
      ],
      "metadata": {
        "id": "KWqvv7nGqmKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.document import Document\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "import uuid\n",
        "\n",
        "# Loaders and initial document processing\n",
        "loaders = [TextLoader(\"./paul_graham_essay.txt\"), TextLoader(\"./state_of_the_union.txt\")]\n",
        "docs = [doc for loader in loaders for doc in loader.load()]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
        "docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# Common setup for vectorstore and retriever\n",
        "def setup_vectorstore_retriever(collection_name, embedding_function):\n",
        "    vectorstore = Chroma(collection_name=collection_name, embedding_function=embedding_function)\n",
        "    store = InMemoryStore()\n",
        "    retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
        "    return vectorstore, store, retriever\n",
        "\n",
        "# Smaller Chunks\n",
        "vectorstore, store, retriever = setup_vectorstore_retriever(\"full_documents\", OpenAIEmbeddings())\n",
        "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
        "# Use small chunk size(400) select from the experiments\n",
        "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
        "sub_docs = [sub_doc for doc in docs for sub_doc in child_text_splitter.split_documents([doc])]\n",
        "\n",
        "# Update metadata for sub documents\n",
        "for sub_doc, doc_id in zip(sub_docs, doc_ids):\n",
        "    sub_doc.metadata[\"doc_id\"] = doc_id\n",
        "\n",
        "# Add documents to vectorstore and store\n",
        "retriever.vectorstore.add_documents(sub_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))\n",
        "\n",
        "# Summaries\n",
        "vectorstore, store, retriever = setup_vectorstore_retriever(\"summaries\", OpenAIEmbeddings())\n",
        "chain = (\n",
        "    {\"doc\": lambda x: x.page_content}\n",
        "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
        "    | ChatOpenAI(max_retries=0)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "summaries = chain.batch(docs, {\"max_concurrency\": 5})\n",
        "summary_docs = [Document(page_content=summary, metadata={\"doc_id\": doc_id}) for summary, doc_id in zip(summaries, doc_ids)]\n",
        "retriever.vectorstore.add_documents(summary_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))\n",
        "\n",
        "# Hypothetical Queries\n",
        "chain = (\n",
        "    {\"doc\": lambda x: x.page_content}\n",
        "    | ChatPromptTemplate.from_template(\"Generate a list of 3 hypothetical questions that the below document could be used to answer:\\n\\n{doc}\")\n",
        "    | ChatOpenAI(max_retries=0, model=\"gpt-3.5-turbo-16k\")\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "hypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})\n",
        "vectorstore, store, retriever = setup_vectorstore_retriever(\"hypo-questions\", OpenAIEmbeddings())\n",
        "question_docs = [Document(page_content=q, metadata={\"doc_id\": doc_id}) for questions, doc_id in zip(hypothetical_questions, doc_ids) for q in questions]\n",
        "retriever.vectorstore.add_documents(question_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))\n",
        "\n",
        "# QA Chain and Results\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
        "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", chain_type_kwargs={\"prompt\": PROMPT}, retriever=retriever, return_source_documents=True)\n"
      ],
      "metadata": {
        "id": "JM2RjYR8N8kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_1 = \"What did the president say about Justice Breyer?\"\n",
        "result_1 = qa_chain({\"query\": question_1})\n",
        "\n",
        "\n",
        "question_2 = \"What did the author do after his time at Y Combinator?\"\n",
        "result_2 = qa_chain({\"query\": question_2})\n",
        "display_eval([result_1, result_2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "xdR-CAkwZDlJ",
        "outputId": "fa268e38-520a-4b0c-cc75-e0a4f8feabdc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Result faithfulness_score answer_relevancy_score context_relevancy_score\n",
              "0  Result 1             0.0000                 0.9628                  0.0000\n",
              "1  Result 2             1.0000                 0.9656                  0.1564"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e6bdc0c-315f-4b4f-b1ad-0c81dec39434\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Result</th>\n",
              "      <th>faithfulness_score</th>\n",
              "      <th>answer_relevancy_score</th>\n",
              "      <th>context_relevancy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Result 1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.9628</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Result 2</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9656</td>\n",
              "      <td>0.1564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e6bdc0c-315f-4b4f-b1ad-0c81dec39434')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e6bdc0c-315f-4b4f-b1ad-0c81dec39434 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e6bdc0c-315f-4b4f-b1ad-0c81dec39434');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f691f836-476c-4deb-baf3-c0c28ac57c78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f691f836-476c-4deb-baf3-c0c28ac57c78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f691f836-476c-4deb-baf3-c0c28ac57c78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline RAG (Chunk Size = 400)\n",
        "| Result  | Faithfulness Score | Answer Relevancy Score | Context Relevancy Score |\n",
        "|---------|--------------------|------------------------|-------------------------|\n",
        "| Result 1| 1.0000             | 0.9426                 | 0.1000                  |\n",
        "| Result 2| 1.0000             | 0.8089                 | 0.0333                  |\n",
        "\n",
        "### Baseline RAG + MultiVector (Chunk Size = 400)\n",
        "\n",
        "| Result  | Faithfulness Score | Answer Relevancy Score | Context Relevancy Score |\n",
        "|---------|--------------------|------------------------|-------------------------|\n",
        "| Result 1| 0.0000             | 0.9628                 | 0.0000                  |\n",
        "| Result 2| 1.0000             | 0.9656                 | 0.1564                  |\n",
        "\n",
        "### Observations\n",
        "\n",
        "1. **Faithfulness Score**:\n",
        "   - Baseline RAG shows consistently high faithfulness scores.\n",
        "   - Baseline RAG + MultiVector exhibits a significant drop in faithfulness in Result 1.\n",
        "\n",
        "2. **Answer Relevancy Score**:\n",
        "   - Baseline RAG has a good answer relevancy score, but it's slightly lower compared to Baseline RAG + MultiVector.\n",
        "   - Baseline RAG + MultiVector demonstrates a higher answer relevancy score in both results.\n",
        "\n",
        "3. **Context Relevancy Score**:\n",
        "   - Baseline RAG shows moderate to low context relevancy scores.\n",
        "   - Baseline RAG + MultiVector shows improvement in context relevancy, particularly in Result 2, but drops to 0 in Result 1.\n",
        "\n",
        "### Insights\n",
        "\n",
        "- **Trade-offs with MultiVector**: The integration of MultiVector with Baseline RAG improves answer relevancy and context relevancy in some cases but may significantly impact faithfulness, as seen in Result 1.\n",
        "- **Contextual Understanding**: Both systems have room for improvement in context relevancy, with Baseline RAG + MultiVector showing potential for higher scores.\n",
        "- **Overall Performance**: The Baseline RAG + MultiVector seems to offer a better balance in answer and context relevancy, but the variability in faithfulness needs to be addressed.\n"
      ],
      "metadata": {
        "id": "TtQV2DQKyQ_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exploration 3: Improving RAG use Tree-of-Thought Prompting**"
      ],
      "metadata": {
        "id": "oisHm2szOk7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the retriever obatined from RAG+MultiVector model, try to improve the\n",
        "# RAG by using the  Tree-of-Thought Prompting\n",
        "\n",
        "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
        "\n",
        "\n",
        "ToT_Promt = \"\"\"Imagine three different experts are answering this question.\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "Then all experts will go on to the next step, etc.\n",
        "If any expert realises they're wrong at any point then they leave.\n",
        "\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "\n",
        "TOT_PROMPT = PromptTemplate(\n",
        "    template=ToT_Promt, input_variables=[\"context\",\"question\"]\n",
        "  )\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  chain_type_kwargs={\"prompt\": TOT_PROMPT},\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True\n",
        "                                  )\n"
      ],
      "metadata": {
        "id": "DTN5wOaQqJpC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_1 = \"What did the president say about Justice Breyer?\"\n",
        "result_1 = qa_chain({\"query\": question_1})\n",
        "question_2 = \"What did the author do after his time at Y Combinator?\"\n",
        "result_2 = qa_chain({\"query\": question_2})\n",
        "display_eval([result_1, result_2])"
      ],
      "metadata": {
        "id": "hyJCkUfi1eUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "1ee02817-e819-49fd-c883-1c62de99f610"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Result faithfulness_score answer_relevancy_score context_relevancy_score\n",
              "0  Result 1             0.0000                 0.8952                  0.0000\n",
              "1  Result 2             0.6667                 0.8972                  0.1564"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6412c4bf-a926-47a4-a6b0-083977e62632\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Result</th>\n",
              "      <th>faithfulness_score</th>\n",
              "      <th>answer_relevancy_score</th>\n",
              "      <th>context_relevancy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Result 1</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8952</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Result 2</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.8972</td>\n",
              "      <td>0.1564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6412c4bf-a926-47a4-a6b0-083977e62632')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6412c4bf-a926-47a4-a6b0-083977e62632 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6412c4bf-a926-47a4-a6b0-083977e62632');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1564aade-7204-40f4-9dc2-c28eb8e97eb1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1564aade-7204-40f4-9dc2-c28eb8e97eb1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1564aade-7204-40f4-9dc2-c28eb8e97eb1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline RAG + MultiVector vs. Baseline RAG + MultiVector + ToT Prompting\n",
        "\n",
        "- The integration of Tree-of-Thought (ToT) Prompting with Baseline RAG + MultiVector **does not show a significant improvement** in performance.\n",
        "- In some scenarios, ToT Prompting **reduces faithfulness and answer relevancy scores** compared to using Baseline RAG + MultiVector alone.\n",
        "- This indicates that ToT Prompting might **not be ideally suited** for the specific dataset used, or it could **require further experimentation** and tuning for better effectiveness.\n"
      ],
      "metadata": {
        "id": "V1ZSZalNfI25"
      }
    }
  ]
}